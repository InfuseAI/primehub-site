<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Prepackage a Base Image and Use It ¬∑ PrimeHub</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="&lt;div class=&quot;ee-only tooltip&quot;&gt;Enterprise"/><meta name="docsearch:version" content="3.10"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Prepackage a Base Image and Use It ¬∑ PrimeHub"/><meta property="og:type" content="website"/><meta property="og:url" content="https://docs.primehub.io/"/><meta property="og:description" content="&lt;div class=&quot;ee-only tooltip&quot;&gt;Enterprise"/><meta property="og:image" content="https://docs.primehub.io/img/primehub_icon.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://docs.primehub.io/img/primehub_icon.svg"/><link rel="shortcut icon" href="/img/PrimeHub_icon_32.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/railscasts.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-123266454-3"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'UA-123266454-3');
            </script><link rel="stylesheet" href="/css/code-block-buttons.css"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Oswald|Lato:400,400i,700"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/prism.css"/><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/PrimeHub_icon_64.png" alt="PrimeHub"/><h2 class="headerTitleWithLogo">PrimeHub</h2></a><a href="/versions"><h3>3.10</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Documentation</a></li><li class=""><a href="/docs/index-zh" target="_self">ÁπÅ‰∏≠Êñá‰ª∂</a></li><li class=""><a href="https://one.primehub.io/" target="_blank">üåü 1-Click Install ‚áó</a></li><li class=""><a href="https://cse.google.com/cse?cx=a1b608e4a3908f544" target="_blank">Search ‚áó</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 id="__docusaurus" class="postHeaderTitle">Prepackage a Base Image and Use It</h1></header><article><div><span><div class="ee-only tooltip">Enterprise
  <span class="tooltiptext">Applicable to Enterprise tier only</span>
</div>
<p>This doc shows how to build a base image and use it. Using the base image has some benefits:</p>
<ol>
<li>If the way you load and use models is the same, these models can share the same base image</li>
<li>If you just want to update the model file, a base image can speed up the building process</li>
</ol>
<p>The idea is that you write a general model serving code and assume the model file is placed under a certain path. And build it as the base image by <code>s2i</code>.</p>
<p>When a model file is ready, use <code>docker</code> to copy the model file into the correct path and build the model deployment image.</p>
<p>In the following section, this doc uses Tensorflow 2 as a simple showcase. The code is under <a href="https://github.com/InfuseAI/model-deployment-examples/tree/master/tensorflow2_prepackage">Github</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="prerequisites"></a><a href="#prerequisites" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prerequisites</h2>
<ul>
<li>Docker: <a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a></li>
<li>S2I (Source-To-Image): <a href="https://github.com/openshift/source-to-image#installation">https://github.com/openshift/source-to-image#installation</a></li>
</ul>
<p>Check everything is ready to go by running:</p>
<pre><code class="hljs css language-bash">s2i usage seldonio/seldon-core-s2i-python3:0.18
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="build-the-base-image-python"></a><a href="#build-the-base-image-python" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Build the Base Image (Python)</h2>
<ul>
<li><p>Please use Python 3.6 (Recommended)</p></li>
<li><p>Write a general model serving code <code>Model.py</code></p>
<pre><code class="hljs css language-python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Model</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        self._model = tf.keras.models.load_model(<span class="hljs-string">'model'</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(self, X, feature_names=None, meta=None)</span>:</span>
        output = self._model.predict(X)
        <span class="hljs-keyword">return</span> output
</code></pre></li>
<li><p>Create a <code>requirements.txt</code> file and write down all required packages</p>
<pre><code class="hljs css language-txt">tensorflow==<span class="hljs-number">2.1</span><span class="hljs-number">.0</span>
</code></pre></li>
<li><p>Create a <code>.s2i</code> folder and create a <code>.s2i/environment</code> file with the following content:</p>
<pre><code class="hljs css language-script"><span class="hljs-attr">MODEL_NAME</span>=Model
<span class="hljs-attr">API_TYPE</span>=REST
<span class="hljs-attr">SERVICE_TYPE</span>=MODEL
<span class="hljs-attr">PERSISTENCE</span>=<span class="hljs-number">0</span>
</code></pre></li>
</ul>
<p>Build the base image by:</p>
<pre><code class="hljs css language-bash"> s2i build <span class="token builtin class-name">.</span> seldonio/seldon-core-s2i-python3:0.18 tensorflow2-prepackage
</code></pre>
<p>(Using <code>seldonio/seldon-core-s2i-python3</code> instead if using Python 3 rather than Python 3.6)</p>
<h2><a class="anchor" aria-hidden="true" id="use-the-base-image-to-build-the-model-deployment-image"></a><a href="#use-the-base-image-to-build-the-model-deployment-image" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Use the Base Image to Build the Model Deployment Image</h2>
<p>Based on our previous base image, whenever you have a model outputted by:</p>
<pre><code class="hljs css language-python">model.save(export_path)
</code></pre>
<p>You can use this base image to build your model deployment image.</p>
<p>First, create a <code>Dockerfile</code>:</p>
<pre><code class="hljs css language-txt"><span class="hljs-keyword">FROM</span> tensorflow2-prepackage
<span class="hljs-keyword">COPY</span><span class="bash"> export_path model </span>
</code></pre>
<p>(Please replace the <code>export_path</code> to your path)</p>
<p>This means you copy your model files into the path that you pre-defined in the base image code.</p>
<p>Then, you can build the model deployment image by:</p>
<pre><code class="hljs css language-bash"><span class="token function">docker</span> build -t tensorflow2-prepackage-model <span class="token builtin class-name">.</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="verify-your-model-deployment-image"></a><a href="#verify-your-model-deployment-image" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Verify Your Model Deployment Image</h2>
<p>In order to verify the image, you can run it:</p>
<pre><code class="hljs css language-bash"><span class="token function">docker</span> run -p <span class="token number">5000</span>:5000 --rm tensorflow2-prepackage-model
</code></pre>
<p>And send a post request by the following format:</p>
<pre><code class="hljs css language-bash"><span class="token function">curl</span> -X POST localhost:5000/api/v1.0/predictions <span class="token punctuation">\</span>
    -H <span class="token string">'Content-Type: application/json'</span> <span class="token punctuation">\</span>
    -d <span class="token string">'{ "data": {"ndarray": [${INPUT_DATA}] } }'</span>
</code></pre>
<p>The <code>${INPUT_DATA}</code> is the data that you can feed into deployed model for prediction.</p>
<blockquote>
<p>The <strong>dimension</strong> of input data must be same as model's input shape.</p>
</blockquote>
<p>For example, if we create our model with a specified <code>input_shape=(4,)</code> by the following definition:</p>
<pre><code class="hljs css language-python">model = tf.keras.models.Sequential([
    keras.layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">4</span>,)),
    ...
    ...
])
</code></pre>
<p>Then, we can send a post request that ${INPUT_DATA} with shape 4.</p>
<pre><code class="hljs css language-bash"><span class="token function">curl</span> -X POST localhost:5000/api/v1.0/predictions <span class="token punctuation">\</span>
    -H <span class="token string">'Content-Type: application/json'</span> <span class="token punctuation">\</span>
    -d <span class="token string">'{ "data": {"ndarray": [[5.1, 3.3, 1.7, 0.5]] } }'</span>
</code></pre>
<p>Or if we create our model with a specified <code>input_shape=(2,2)</code> by the following definition:</p>
<pre><code class="hljs css language-python">model = tf.keras.models.Sequential([
    keras.layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)),
    ...
    ...
])
</code></pre>
<p>Then, we can also send a post request that ${INPUT_DATA} with shape (2,2).</p>
<pre><code class="hljs css language-bash"><span class="token function">curl</span> -X POST localhost:5000/api/v1.0/predictions <span class="token punctuation">\</span>
    -H <span class="token string">'Content-Type: application/json'</span> <span class="token punctuation">\</span>
    -d <span class="token string">'{ "data": {"ndarray": [[[5.1, 3.3], [1.7, 0.5]]] } }'</span>
</code></pre>
<p>After sending the post request, we can obtain the response output in the following format:</p>
<pre><code class="hljs css language-bash"><span class="token punctuation">{</span><span class="token string">"data"</span>:<span class="token punctuation">{</span><span class="token string">"names"</span>:<span class="token punctuation">[</span><span class="token punctuation">]</span>,<span class="token string">"ndarray"</span>:<span class="token punctuation">[</span><span class="token variable">${PREDICTION_RESULT}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token string">"meta"</span>:<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
</code></pre>
<p>The <code>${PREDICTION_RESULT}</code> is a list to represent the prediction value.</p>
<p>For example, the following output shows three prediction values in each class.</p>
<pre><code class="hljs css language-bash"><span class="token punctuation">{</span><span class="token string">"data"</span>:<span class="token punctuation">{</span><span class="token string">"names"</span>:<span class="token punctuation">[</span><span class="token punctuation">]</span>,<span class="token string">"ndarray"</span>:<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.093</span>,-0.519,-8.918<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token string">"meta"</span>:<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
</code></pre>
<p>After verifying your model deployment image, now you can use this image in the PrimeHub model deployment feature.</p>
<h2><a class="anchor" aria-hidden="true" id="share-your-base-image"></a><a href="#share-your-base-image" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Share Your Base Image</h2>
<p>Share your base image by pushing it to a docker registry.</p>
<p>Therefore, others can re-use the model serving code again. They can share the same base image and build a model deployment image by <code>docker</code>.</p>
</span></div></article></div><div class="docs-prevnext"></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#build-the-base-image-python">Build the Base Image (Python)</a></li><li><a href="#use-the-base-image-to-build-the-model-deployment-image">Use the Base Image to Build the Model Deployment Image</a></li><li><a href="#verify-your-model-deployment-image">Verify Your Model Deployment Image</a></li><li><a href="#share-your-base-image">Share Your Base Image</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/PrimeHub_icon_128.png" alt="PrimeHub" width="66" height="58"/></a><div><h5></h5><a href="https://discord.gg/CrAxQznedH">Discord</a><a href="https://github.com/infuseai">GitHub</a><a href="https://medium.com/infuseai">Medium</a><a href="https://www.facebook.com/InfuseAI">Facebook</a><a href="https://www.katacoda.com/infuseai">Katacoda</a></div><div><h5>More</h5><a href="https://infuseai.io">About InfuseAI</a><a href="/docs/comparison">Community | Enterprise | Deploy</a><a href="https://docs.google.com/forms/d/e/1FAIpQLSe_Z8JfIbYnvhOampGN_XXle4d3GVX04E8evnNI_Py3abth-A/viewform">Request Trial</a></div></section><section class="copyright">Copyright ¬© 2022 InfuseAI</section></footer></div></body></html>